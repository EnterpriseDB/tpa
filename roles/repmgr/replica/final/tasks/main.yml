---

# Copyright Â© 2ndQuadrant Limited <info@2ndquadrant.com>

# This role is applied to every postgres replica instance.
#
# A replica must have a valid PGDATA (cloned from the primary), must
# have a valid recovery.conf, must be streaming from the primary, and
# must be correctly registered with repmgr.
#
# First: do we have a valid PGDATA? If not, run repmgr standby clone.

- include_tasks: clone.yml
  when:
    not pgdata_initialised

# Do we have a valid recovery.conf?
#
# We have the information required to create one, but we would prefer to
# let repmgr handle it for us, so for now we do nothing beyond checking
# that the file exists (out of an abundance of caution).
#
# If we arrive here after cloning PGDATA above, we won't have access to
# facts collected earlier during cluster_discovery (this instance would
# have been skipped at the time). But we must ensure that recovery.conf
# is present before starting Postgres, so the following tests must work
# whether cluster_facts is populated or not.

- include_tasks: recovery.yml
  when:
    recovery_settings is empty
  vars:
    recovery_settings: >
      {{ cluster_facts|try_subkey('replica.recovery_settings', {}) }}

# Next we must check if the replica is streaming properly, for which we
# need Postgres to be running. If it's already running, the tasks below
# should succeed immediately.

- name: Ensure that Postgres is running
  service:
    name: "{{ postgres_service_name }}"
    state: started

- name: Wait for Postgres to become available
  command: /etc/tpa/postgres-monitor "{{ postgres_dsn }}"
  changed_when: False
  become_user: "{{ postgres_user }}"
  become: yes

# Now we can collect cluster_facts for this instance if they are not yet
# available, and subsequent sanity checks can depend on the presence of
# these facts.

- include_role: name=postgres/facts
  when:
    cluster_facts is empty

# Now we can check that this instance is in fact a replica, and has a
# reasonable configuration.

- include_tasks: check-replica.yml

# Is this instance correctly registered with repmgr?
#
# If we are streaming from the primary, then our view of nodes is
# authoritative. However, if we are not streaming (whether because we
# are still in archive recovery, or because of a configuration error),
# the contents of nodes collected above may be misleading. As a stopgap
# measure, we query the upstream server directly.

- name: Check if this instance is registered as a replica
  postgresql_query:
    conninfo: "{{ hostvars[upstream_primary].repmgr_node_dsn }}"
    query: >
      SELECT (case when type='standby' then 'replica' else type end) as type
      FROM repmgr.nodes
      WHERE node_name='{{ inventory_hostname }}' AND active
  register: registration
  become_user: "{{ postgres_user }}"
  become: yes

- name: Run repmgr standby register
  command: >
    {{ postgres_bin_dir }}/repmgr standby register --verbose \
      --upstream-node-id "{{ hostvars[upstream].node }}" \
      -f "{{ repmgr_conf_file }}" --force --wait-sync=0
  become_user: "{{ postgres_user }}"
  become: true
  when:
    registration.rowcount == 0 or registration.type != 'replica' or rehydrate|default(false)|bool
