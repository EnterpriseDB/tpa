---

# Â© Copyright EnterpriseDB UK Limited 2015-2024 - All rights reserved.

# On a new cluster we start by creating the Postgres cluster before
# patroni, at this stage the DCS has no info about the cluster
# but the configuration should be defined. Patroni is able to use
# the existing initialised database and config, and create a new
# DCS config.

# So first of all we read the cluster state from the DCS, then we
# start patroni on the primary if the DCS is empty. This ensures that the
# expected Postgres node is set as leader in the DCS. Then once the DCS has
# correct information we can start Patroni on the standbys who will be
# assigned with the correct role in the DCS (`replica`)

# Make Patroni take management over on the primary
# We need to start with the primary so we avoid that Patroni would promote a
# replica when taking over the cluster management
- block:
  - include_tasks: config.yml

  - include_role:
      name: patroni/service
      tasks_from: transition
    vars:
      to_state: started
  when: >
    'primary' in role
    and (patroni_cluster.members is not defined
      or patroni_cluster.members is empty)

# Update facts which will be used by Patroni on the replicas
# That's required so the replicas will have the updated facts when being taken
# over by Patroni
- include_role:
    name: patroni/facts
    tasks_from: gather

# Make Patroni take management over on the replicas
- block:
  - include_tasks: config.yml

  - include_role:
      name: patroni/service
      tasks_from: transition
    vars:
      to_state: started

  when: >
    'replica' in role
    and patroni_cluster.members|selectattr('Member', 'eq', inventory_hostname)|list is empty

# This will take care of "stopping" the `postgres` systemd unit and making
# Patroni start Postgres through `pg_ctl`
- name: Issue a postgresql restart so Patroni can take it over
  include_role:
    name: patroni/api
    tasks_from: restart
  run_once: true
  when:
    patroni_initialised
