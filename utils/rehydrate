#!/bin/bash
#
# Given a cluster and an instance name, "rehydrates" the instance as
# described below:
#
# 1. Ensures that all extra volumes attached to the instance are tagged
#    correctly and set to not be deleted on termination of the instance.
# 2. Terminates the instance and waits for the operation to complete.
# 3. Provisions a replacement for the instance.
# 4. Redeploys software on the new instance.
#
# Example: utils/rehydrate test/cluster instancename

IFS=
set -e -u

utils=$(dirname $0)

cluster=${1:?No cluster specified}
shift

instance=${1:?No instance specified}
shift

cluster_dir=$cluster
if [[ ${cluster_dir:0:1} != '/' ]]; then
    clusters=$(realpath $utils/../clusters);
    cluster=$(echo $cluster|sed 's,^clusters/,,')
    cluster_dir="$clusters/$cluster"
fi

if [ ! -d $cluster_dir ]; then
    echo "Can't find directory $cluster_dir"
    exit
fi

# Terminate the old instance after performing sanity checks.

$utils/ansible-playbook \
    $utils/../platforms/aws/terminate-for-rehydration.yml \
    -i $cluster_dir/inventory \
    -e cluster=$cluster_dir \
    --limit "$instance"

# Provision a replacement for the terminated instance.
#
# XXX We don't have a good way to check that, for each volume that was
# retained after termination, we have «attach_existing: yes» set in the
# config.yml. Also, despite checking the volumes in the previous step,
# it may be prudent to also check during provisioning that we did find
# volumes corresponding to attach_existing volume definitions. (This is
# a lower risk because the correct volumes are there somewhere.)

$utils/ansible-playbook \
    $utils/../platforms/aws/provision.yml \
    -e cluster=$cluster_dir

# Redeploy to the new instance.

$utils/ansible-playbook \
    $cluster_dir/deploy.yml \
    -i $cluster_dir/inventory \
    --vault-password-file $cluster_dir/vault/vault_pass.txt \
    -e cluster=$cluster_dir \
    -e deploy_hosts="$instance" \
    "$@"
