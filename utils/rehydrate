#!/bin/bash
#
# Given a cluster and an instance name, "rehydrates" the instance as
# described below:
#
# 1. Ensures that all extra volumes attached to the instance are tagged
#    correctly and set to not be deleted on termination of the instance.
# 2. Terminates the instance and waits for the operation to complete.
# 3. Provisions a replacement for the instance.
# 4. Redeploys software on the new instance.
#
# Example: utils/rehydrate test/cluster instancename

IFS=
set -e -u

utils=$(dirname $0)

cluster=${1:?No cluster specified}
shift

instance=${1:?No instance specified}
shift

DESTROY=no
if [ "$1" = "I_REALLY_WANT_TO_DESTROY_MY_ENTIRE_CLUSTER=yes" ]; then
    DESTROY=yes
    shift
fi

cluster_dir=$cluster
if [[ ${cluster_dir:0:1} != '/' ]]; then
    clusters=$(realpath $utils/../clusters);
    cluster=$(echo $cluster|sed 's,^clusters/,,')
    cluster_dir="$clusters/$cluster"
fi

if [ ! -d $cluster_dir ]; then
    echo "Can't find directory $cluster_dir"
    exit
fi

# Terminate the old instance after performing sanity checks.

$utils/ansible-playbook \
    $utils/../platforms/aws/terminate-for-rehydration.yml \
    -e i_really_want_to_destroy_my_entire_cluster=$DESTROY \
    -i $cluster_dir/inventory \
    -e cluster=$cluster_dir \
    --limit "$instance"

# Provision a replacement for the terminated instance.
#
# XXX We don't have a good way to check that, for each volume that was
# retained after termination, we have «attach_existing: yes» set in the
# config.yml. Also, despite checking the volumes in the previous step,
# it may be prudent to also check during provisioning that we did find
# volumes corresponding to attach_existing volume definitions. (This is
# a lower risk because the correct volumes are there somewhere.)

$utils/provision $cluster_dir

# XXX I don't know why, but running deploy immediately after provision,
# even with the ec2 cache invalidated, a custom SSH port set, and a new
# known_hosts file written sometimes results in a key validation prompt
# or failure. Sleeping for even a little while makes it go away. Anyway
# it's safe to rerun deploy on the cluster using the command below.

echo "Allowing the CPU to cool down before deployment"
sleep 70

# Redeploy to the new instance.

$utils/deploy $cluster_dir -e deploy_hosts="$instance" "$@"
