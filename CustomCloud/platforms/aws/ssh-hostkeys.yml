---

# First, we generate as many SSH host keys as we have instances.

- include: ../common/ssh-hostkeys.yml

# This task is always inappropriately marked "changed"; see
# https://github.com/ansible/ansible-modules-extras/issues/2618 for
# details.

- name: Create an S3 bucket for this cluster
  s3_bucket:
    name: "{{ cluster_bucket }}"
    region: "{{ regions[0] }}"
    state: present
    tags: "{{
      cluster_tags|combine({
        'CreatingCluster': cluster_name
      })
    }}"
    policy: >
      {
        "Version": "2012-10-17",
        "Statement": [
          {
            "Sid": "InstanceRolesOnly",
            "Action": ["s3:GetObject"],
            "Resource": "arn:aws:s3:::{{cluster_bucket}}/*",
            "Effect": "Allow",
            "Principal": {
              "AWS": [ "{{ instance_profile_role }}" ]
            }
          }
        ]
      }
  
- name: Set S3 bucket contents to expire in a week
  s3_lifecycle:
    name: "{{ cluster_bucket }}"
    expiration_days: 7
    status: enabled
    state: present

# We generated host keys into hostkeys/ssh_host_$type_key{,.pub};
# we now upload those to hostkeys/$type{,.pub}.txt in S3.

- name: Upload SSH host key files
  s3:
    bucket: "{{ cluster_bucket }}"
    object: "hostkeys/{{ item.0 }}{{ item.1 }}.txt"
    src: "{{ cluster_dir }}/hostkeys/ssh_host_{{ item.0 }}_key{{ item.1 }}"
    overwrite: different
    expiration: 3600
    mode: put
  with_nested:
    - ["rsa", "ecdsa"]
    - ["", ".pub"]
  register: keyurls
